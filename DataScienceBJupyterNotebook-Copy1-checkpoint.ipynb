{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "462de278",
   "metadata": {},
   "source": [
    "Data Science Tools and Ecosystem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73b6f4e",
   "metadata": {},
   "source": [
    "[//]: # Data Science Tools and Ecosystem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8363f5c",
   "metadata": {},
   "source": [
    "#In this notebook, Data Science Tools and Ecosystem are summarized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105bc76f",
   "metadata": {},
   "source": [
    "[#]In this notebook, Data Science Tools and Ecosystem are summarized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5badc0",
   "metadata": {},
   "source": [
    "'#'In this notebook, Data Science Tools and Ecosystem are summarized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3549851",
   "metadata": {},
   "source": [
    "\"#In this notebook, Data Science Tools and Ecosystem are summarized.\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8092a5f",
   "metadata": {},
   "source": [
    "\"\"<h1>In this notebook, Data Science Tools and Ecosystem are summarized.<h1>\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e636017c",
   "metadata": {},
   "source": [
    "# Data Science Languages\n",
    "\n",
    "The following are some of the most widely used languages for data science:\n",
    "\n",
    "- **Python**: Python is a general-purpose, high-level, and dynamic programming language that supports multiple paradigms such as object-oriented, functional, and procedural. Python has a rich set of libraries and frameworks for data analysis, visualization, machine learning, and web development, such as NumPy, pandas, matplotlib, scikit-learn, TensorFlow, and Django.\n",
    "- **R**: R is a specialized language for statistical computing and graphics. R provides a comprehensive environment for data manipulation, exploration, modeling, and visualization. R has a large and active community of users and developers who contribute to thousands of packages that extend its functionality for various domains and applications.\n",
    "- **SQL**: SQL (Structured Query Language) is a domain-specific language for managing and querying data stored in relational databases. SQL allows data scientists to perform operations such as filtering, aggregating, joining, and transforming data from multiple tables using a declarative syntax. SQL is also widely supported by many tools and platforms that integrate with databases.\n",
    "- **Julia**: Julia is a modern, high-performance, and expressive language for scientific computing. Julia combines the speed of compiled languages like C with the productivity and interactivity of interpreted languages like Python. Julia also features multiple dispatch, metaprogramming, and a powerful type system that enable writing elegant and generic code. Julia has a growing ecosystem of packages for data science, such as DataFrames.jl, Plots.jl, Flux.jl, and JuMP.jl.\n",
    "- **Scala**: Scala is a multi-paradigm language that integrates both object-oriented and functional programming features. Scala runs on the Java Virtual Machine (JVM) and interoperates seamlessly with Java libraries and frameworks. Scala is also the primary language for Apache Spark, a distributed computing platform for large-scale data processing and machine learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4372ed44",
   "metadata": {},
   "source": [
    "# Data Science Libraries for Python\n",
    "\n",
    "Python is one of the most widely used languages for data science, thanks to its large and diverse collection of libraries that offer various functionalities and features. Here are some of the most essential libraries that every data scientist should know and use:\n",
    "\n",
    "- **NumPy**: NumPy is a library for performing fast and efficient numerical computations on multidimensional arrays and matrices. It supports various mathematical operations, such as linear algebra, Fourier transform, random number generation, and more. NumPy is the basis for many other data science libraries, such as pandas, SciPy, and scikit-learn.\n",
    "- **pandas**: pandas is a library for data manipulation and analysis. It provides high-performance data structures, such as Series and DataFrame, that allow working with labeled and relational data in a intuitive way. pandas also offers tools for reading and writing data from various formats, such as CSV, Excel, JSON, SQL, and more. pandas enables data cleaning, reshaping, merging, grouping, filtering, aggregating, and visualizing data with ease.\n",
    "- **SciPy**: SciPy is a library for scientific computing that builds on NumPy. It provides modules for various domains and applications, such as optimization, integration, interpolation, statistics, signal processing, spatial analysis, image processing, and more. SciPy also integrates with other popular libraries, such as matplotlib and scikit-learn.\n",
    "- **matplotlib**: matplotlib is a library for creating high-quality plots and graphs from data. It supports various types of charts, such as line plots, bar charts, histograms, scatter plots, pie charts, box plots, and more. matplotlib also allows customizing the appearance of the plots, such as colors, labels, legends, axes, grids, etc. matplotlib can also be used in conjunction with other libraries, such as pandas and seaborn, to enhance the visualization capabilities.\n",
    "- **seaborn**: seaborn is a library for statistical data visualization that complements matplotlib. It provides a high-level interface for creating attractive and informative plots from data. seaborn also supports various types of plots that are useful for exploring the distribution, correlation, and relationship of data, such as histograms, density plots, joint plots, pair plots, heatmaps, regression plots, etc. seaborn also integrates well with pandas and can use its data structures as inputs.\n",
    "- **scikit-learn**: scikit-learn is a library for machine learning that provides a consistent and user-friendly interface for various algorithms and models. scikit-learn supports various tasks in machine learning, such as classification, regression,\n",
    "clustering,\n",
    "dimensionality reduction,\n",
    "feature extraction,\n",
    "model selection,\n",
    "and evaluation.\n",
    "scikit-learn also offers tools for preprocessing,\n",
    "pipelining,\n",
    "and cross-validation of data.\n",
    "scikit-learn is built on NumPy,\n",
    "SciPy,\n",
    "and matplotlib\n",
    "and works well with pandas\n",
    "and other libraries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd038f9",
   "metadata": {},
   "source": [
    "# Data Science Tools Table\n",
    "\n",
    "| Name | Category | Description |\n",
    "| ---- | -------- | ----------- |\n",
    "| SAS | Statistical software | A software suite for data analysis, manipulation, visualization, and reporting. It supports various statistical techniques, such as regression, clustering, classification, and forecasting. |\n",
    "| Apache Spark | Distributed computing platform | A fast and scalable framework for large-scale data processing and machine learning. It supports various languages, such as Python, Scala, Java, and R. It also provides libraries for SQL, streaming, graph analysis, and more. |\n",
    "| BigML | Machine learning platform | A cloud-based platform that offers end-to-end solutions for data preparation, feature engineering, model building, evaluation, and deployment. It supports various supervised and unsupervised learning algorithms, such as decision trees, logistic regression, k-means, and anomaly detection. |\n",
    "| D3.js | Data visualization library | A JavaScript library for creating interactive and dynamic data visualizations in web browsers. It allows manipulating the document object model (DOM) based on data and applying various graphical effects, such as transitions, animations, and interactions. |\n",
    "| MATLAB | Numerical computing environment | A software environment for performing numerical computations and simulations. It supports various mathematical functions, such as matrix operations, linear algebra, optimization, signal processing, and more. It also provides tools for data analysis, visualization, and application development. |\n",
    "| Excel | Spreadsheet software | A software application for creating and working with spreadsheets. It allows organizing, manipulating, calculating, and analyzing data using formulas and functions. It also provides features for data visualization, such as charts, graphs, and pivot tables. |\n",
    "| NLTK | Natural language processing library | A Python library for working with human language data. It provides modules for various tasks in natural language processing (NLP), such as tokenization, stemming, tagging, parsing, sentiment analysis, and more. It also includes a collection of corpora and lexical resources. |\n",
    "| TensorFlow | Machine learning framework | An open-source framework for developing and deploying machine learning models. It supports various types of neural networks and deep learning architectures. It also provides tools for data preprocessing, model training, evaluation, optimization, and inference. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c985a20c",
   "metadata": {},
   "source": [
    "# Arithmetic Expression Examples\n",
    "\n",
    "An arithmetic expression is a combination of numbers and arithmetic operators, such as addition (+), subtraction (-), multiplication (*), division (/), and exponentiation (^). An arithmetic expression can be evaluated to a single numerical value by following the order of operations (PEMDAS).\n",
    "\n",
    "Here are some examples of arithmetic expressions and their evaluations:\n",
    "\n",
    "- 3 + 5 * 2: This expression has two operators, addition and multiplication. According to the order of operations, we need to perform multiplication before addition. So, we first multiply 5 and 2 to get 10, and then add 3 to get 13. Therefore, 3 + 5 * 2 = 13.\n",
    "- (4 - 1) ^ 2 / 3: This expression has four operators, parentheses, exponentiation, subtraction, and division. According to the order of operations, we need to perform the operations inside the parentheses first, then exponentiation, then division, and then subtraction. So, we first subtract 1 from 4 to get 3, then raise it to the power of 2 to get 9, then divide it by 3 to get 3, and then subtract it from 4 to get 1. Therefore, (4 - 1) ^ 2 / 3 = 1.\n",
    "- (7 + 3) / (2 * (5 - 1)): This expression has five operators, parentheses, addition, subtraction, multiplication, and division. According to the order of operations, we need to perform the operations inside the innermost parentheses first, then the outermost parentheses, and then division. So, we first subtract 1 from 5 to get 4, then multiply it by 2 to get 8, then add 7 and 3 to get 10, and then divide it by 8 to get $$\\frac{5}{4}$$. Therefore, (7 + 3) / (2 * (5 - 1)) = $$\\frac{5}{4}$$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "198604e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of multiplying 5 and 3 is 15\n",
      "The result of adding 5 and 3 is 8\n"
     ]
    }
   ],
   "source": [
    "# Define two numbers\n",
    "a = 5\n",
    "b = 3\n",
    "\n",
    "# Multiply the numbers and store the result in a variable\n",
    "c = a * b\n",
    "\n",
    "# Print the result of multiplication\n",
    "print(\"The result of multiplying\", a, \"and\", b, \"is\", c)\n",
    "\n",
    "# Add the numbers and store the result in another variable\n",
    "d = a + b\n",
    "\n",
    "# Print the result of addition\n",
    "print(\"The result of adding\", a, \"and\", b, \"is\", d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "951f1bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 minutes is equal to 2.0 hours\n"
     ]
    }
   ],
   "source": [
    "# Define the number of minutes\n",
    "minutes = 120\n",
    "\n",
    "# Convert minutes to hours by dividing by 60\n",
    "hours = minutes / 60\n",
    "\n",
    "# Print the result of conversion\n",
    "print(minutes, \"minutes is equal to\", hours, \"hours\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049db2d8",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "\n",
    "- Define the problem statement and the scope of the project\n",
    "- Explore and clean the data\n",
    "- Perform exploratory data analysis and visualization\n",
    "- Build and evaluate machine learning models\n",
    "- Communicate and present the results and insights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a26f6c",
   "metadata": {},
   "source": [
    "# Author\n",
    "\n",
    "Alice Smith\n",
    "Data Scientist at XYZ Inc.\n",
    "alice.smith@xyz.com\n",
    "https://alice-smith.github.io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb89e50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://artifactory.micron.com/artifactory/api/pypi/zextpythonorg-pypi-rel-remote/simple\n",
      "Collecting nbss-upload\n",
      "  Downloading https://artifactory.micron.com/artifactory/api/pypi/zextpythonorg-pypi-rel-remote/packages/packages/9d/c8/8b9c9598268e6f3a672df9b5d7708e98cd9cb2a7b9537ae0da1b7b7ff920/nbss_upload-0.1-py3-none-any.whl (3.7 kB)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from nbss-upload) (2.25.1)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->nbss-upload) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->nbss-upload) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->nbss-upload) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->nbss-upload) (2020.12.5)\n",
      "Installing collected packages: nbss-upload\n",
      "Successfully installed nbss-upload-0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nbss-upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce8712a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-9fcf32af4011>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-9fcf32af4011>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    nbss-upload.r\"DataScienceBJupyterNotebook-Copy1-checkpoint.ipynb\"\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "nbss-upload.r\"DataScienceBJupyterNotebook-Copy1-checkpoint.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cbe3108",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nbss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-e199a5aa53fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnbss\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mupload\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataScienceBJupyterNotebook\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mCopy1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mipynb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'nbss' is not defined"
     ]
    }
   ],
   "source": [
    "nbss-upload.DataScienceBJupyterNotebook-Copy1-checkpoint.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6733fdd5",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-b643ff68d4f5>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-b643ff68d4f5>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    nbss-upload DataScienceBJupyterNotebook-Copy1-checkpoint.ipynb\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "nbss-upload DataScienceBJupyterNotebook-Copy1-checkpoint.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd9aaa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
